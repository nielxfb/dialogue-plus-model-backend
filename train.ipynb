{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier, accuracy\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317840</th>\n",
       "      <td>father day o</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371775</th>\n",
       "      <td>who authorized you question my authority gogo ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90822</th>\n",
       "      <td>pm met nicola sturgeon in edinburgh today the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618920</th>\n",
       "      <td>yours are dumb because most other subway stati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701429</th>\n",
       "      <td>the tree angela see the seal guide to house re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228868</th>\n",
       "      <td>none of the two maps are suitable imo if any m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211548</th>\n",
       "      <td>by a person with no life and takes it up the ass</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628753</th>\n",
       "      <td>do they get the same old warning or... is this...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470816</th>\n",
       "      <td>jimmy these are not for whatever be some pieta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39357</th>\n",
       "      <td>pee wee in batman returns with danny devito da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content  Label\n",
       "317840                                       father day o      0\n",
       "371775  who authorized you question my authority gogo ...      0\n",
       "90822   pm met nicola sturgeon in edinburgh today the ...      0\n",
       "618920  yours are dumb because most other subway stati...      1\n",
       "701429  the tree angela see the seal guide to house re...      1\n",
       "...                                                   ...    ...\n",
       "228868  none of the two maps are suitable imo if any m...      0\n",
       "211548   by a person with no life and takes it up the ass      1\n",
       "628753  do they get the same old warning or... is this...      1\n",
       "470816  jimmy these are not for whatever be some pieta...      1\n",
       "39357   pee wee in batman returns with danny devito da...      0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('HateSpeechDatasetBalanced.csv').sample(n=5000)\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    "    elif tag.startswith('V'):\n",
    "        return 'v'\n",
    "    elif tag.startswith('N'):\n",
    "        return 'n'\n",
    "    elif tag.startswith('R'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n'\n",
    "\n",
    "def preprocess_words(words):\n",
    "    words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "    words = [word for word in words if word.lower() not in string.punctuation]\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "\n",
    "    word_tag = pos_tag(words)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in word_tag]\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.90%\n"
     ]
    }
   ],
   "source": [
    "tweets = df['Content']\n",
    "labels = df['Label']\n",
    "\n",
    "word_list = []\n",
    "\n",
    "for sentence in tweets:\n",
    "    check_words = word_tokenize(sentence)\n",
    "    for word in check_words:\n",
    "        word_list.append(word)\n",
    "\n",
    "word_list = preprocess_words(word_list)\n",
    "\n",
    "labeled_data = zip(tweets, labels)\n",
    "\n",
    "feature_sets = []\n",
    "\n",
    "for tweet, label in labeled_data:\n",
    "    feature = {}\n",
    "\n",
    "    check_words = word_tokenize(tweet)\n",
    "    check_words = preprocess_words(check_words)\n",
    "\n",
    "    for word in word_list:\n",
    "        feature[word] = word in check_words\n",
    "\n",
    "    feature_sets.append((feature, label))\n",
    "\n",
    "random.shuffle(feature_sets)\n",
    "\n",
    "train_count = int(len(feature_sets) * 0.8)\n",
    "train_set = feature_sets[:train_count]\n",
    "test_set = feature_sets[train_count:]\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "print(f\"Accuracy: {accuracy(classifier, test_set) * 100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('model.pickle', 'wb')\n",
    "pickle.dump(classifier, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
